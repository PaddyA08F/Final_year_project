{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cg3aekRznPPM",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Practical Applications with Neural Network Surrogates\n",
    "\n",
    "General idea of most applications: replace high fidelity model, usually correspoding to the solution of a PDE, with the network model trained with a set generate by solving the PDE $N$ times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import seaborn as sb\n",
    "\n",
    "# Adapt this import to your specific directory tree.\n",
    "from Common import NeuralNet, fit\n",
    "torch.manual_seed(42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1bnu6a6ynPPP",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def initial_condition(x, y):\n",
    "  # Generate perturbed initial condition.\n",
    "  ic = torch.zeros_like(x)\n",
    "  for i in range(y.shape[0]):\n",
    "      ic = ic + y[i] * torch.sin((2 + i) * np.pi * x) \n",
    "  ic = ic / torch.mean(ic ** 2)**0.5\n",
    "  return ic\n",
    "\n",
    "\n",
    "def solve_heat_eq(y):\n",
    "  # http://hplgit.github.io/num-methods-for-PDEs/doc/pub/diffu/html/._diffu-solarized001.html\n",
    "  # Typical heat equation solver.\n",
    "  nx = 51\n",
    "  x = torch.linspace(0,1, nx)\n",
    "  T = 0.01\n",
    "  ic = initial_condition(x,y)\n",
    "\n",
    "  diff = 1\n",
    "  dx = x[1] - x[0]\n",
    "  dt = 0.5 * dx ** 2 / diff\n",
    "\n",
    "  F = diff * dt / dx ** 2\n",
    "  nt = int((T / dt))\n",
    "  nx = x.shape[0]\n",
    "\n",
    "  u_old = torch.clone(ic)\n",
    "  u_new = torch.zeros_like(ic)\n",
    "\n",
    "  for k in range(1, nt):\n",
    "      for i in range(1, nx - 1):\n",
    "          u_new[i] = (\n",
    "              u_old[i] + F * (u_old[i + 1] - 2 * u_old[i] + u_old[i - 1]))\n",
    "      u_new[0] = 0\n",
    "      u_new[-1] = 0\n",
    "\n",
    "      u_old[:] = u_new\n",
    "\n",
    "  flux = -diff * (u_new[0] - u_new[1]) / dx\n",
    "  return flux, (x, ic, u_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 747
    },
    "executionInfo": {
     "elapsed": 11570,
     "status": "ok",
     "timestamp": 1682413827284,
     "user": {
      "displayName": "Victor Armegioiu",
      "userId": "10988735183621484296"
     },
     "user_tz": -120
    },
    "id": "asOH7rSgnPPP",
    "outputId": "9de670da-ad89-4383-aca8-969e031d2f42",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############################\n",
      "Generating Training Set\n",
      "###############################\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 26\u001B[0m\n\u001B[1;32m     24\u001B[0m axs[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mgrid(\u001B[38;5;28;01mTrue\u001B[39;00m, which\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mboth\u001B[39m\u001B[38;5;124m\"\u001B[39m, ls\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_samples):\n\u001B[0;32m---> 26\u001B[0m     f, (x, ic, u_end) \u001B[38;5;241m=\u001B[39m \u001B[43msolve_heat_eq\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m[\u001B[49m\u001B[43mj\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     27\u001B[0m     training_set[j, :d] \u001B[38;5;241m=\u001B[39m y[j]\n\u001B[1;32m     28\u001B[0m     training_set[j, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m=\u001B[39m f\n",
      "Cell \u001B[0;32mIn[2], line 32\u001B[0m, in \u001B[0;36msolve_heat_eq\u001B[0;34m(y)\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, nt):\n\u001B[1;32m     30\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, nx \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m     31\u001B[0m         u_new[i] \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m---> 32\u001B[0m             \u001B[43mu_old\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mF\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mu_old\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mu_old\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mu_old\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     33\u001B[0m     u_new[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     34\u001B[0m     u_new[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "print(\"###############################\")\n",
    "print(\"Generating Training Set\")\n",
    "torch.manual_seed(12446)\n",
    "n_samples = 100\n",
    "sobol = False\n",
    "min_inputs = -5\n",
    "max_inputs = 5\n",
    "d = 2\n",
    "# Inputs for generating the training set are in [-5,5]\n",
    "if not sobol:\n",
    "    y_rand = torch.rand((n_samples, d))\n",
    "    y = (max_inputs - min_inputs) * y_rand + min_inputs\n",
    "else:\n",
    "    sob_eng = torch.quasirandom.SobolEngine(d)\n",
    "    sob_eng.fast_forward(1)\n",
    "    y_sob = sob_eng.draw(n_samples)\n",
    "    y = (max_inputs - min_inputs)*y_sob + min_inputs\n",
    "training_set = torch.zeros((n_samples, y.shape[1] + 1))\n",
    "\n",
    "\n",
    "print(\"###############################\")\n",
    "fig, axs = plt.subplots(2, dpi=150)\n",
    "axs[0].grid(True, which=\"both\", ls=\":\")\n",
    "axs[1].grid(True, which=\"both\", ls=\":\")\n",
    "for j in range(n_samples):\n",
    "    f, (x, ic, u_end) = solve_heat_eq(y[j])\n",
    "    training_set[j, :d] = y[j]\n",
    "    training_set[j, -1] = f\n",
    "    axs[0].plot(x, ic)\n",
    "    axs[1].plot(x, u_end)\n",
    "    \n",
    "axs[0].set(ylabel='u')\n",
    "axs[1].set(xlabel='x', ylabel='u')\n",
    "axs[0].set_title(\"Initial Condition\")\n",
    "axs[1].set_title(\"Solution at T = 0.01\")\n",
    "for ax in fig.get_axes():\n",
    "    ax.label_outer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mpAgg2gKnPPQ",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Setup dataset for training.\n",
    "if not sobol:\n",
    "    inputs = y_rand\n",
    "else:\n",
    "    inputs = y_sob\n",
    "output = training_set[:, -1].reshape(-1, 1)\n",
    "\n",
    "batch_size = inputs.shape[0]\n",
    "training_set_loader = DataLoader(\n",
    "    torch.utils.data.TensorDataset(inputs, output), \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOKMPX_N0Bhw",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Neural Surrogates\n",
    "\n",
    "Since actually solving PDEs from scratch for every perturbation of the initial condition is quite an expensive process, we shall instead opt for a neural approximation. \n",
    "\n",
    "\n",
    "This amounts to learning a neural approximant (parameterized by $\\theta$)\n",
    "\n",
    "$$\n",
    "\\hat{L}_\\theta: y \\mapsto \\hat{L}_\\theta^\\Delta(y), \\quad y\\in[0,1]^d\n",
    "$$\n",
    "\n",
    "which is trained to map $y$'s to pre-computed observables at a pre-determined number of query points (i.e. your dataset).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17824,
     "status": "ok",
     "timestamp": 1682416020638,
     "user": {
      "displayName": "Victor Armegioiu",
      "userId": "10988735183621484296"
     },
     "user_tz": -120
    },
    "id": "E6RkEnR6zjgs",
    "outputId": "ecc1cf4c-cf4c-4baa-a124-3754c06b2760",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Setup model and optimizer.\n",
    "model = NeuralNet(input_dimension=inputs.shape[1], \n",
    "                  output_dimension=output.shape[1], \n",
    "                  n_hidden_layers=4, \n",
    "                  neurons=20, \n",
    "                  regularization_param=0.0, \n",
    "                  regularization_exp=2,\n",
    "                  retrain_seed=128)\n",
    "\n",
    "optimizer_ = optim.LBFGS(\n",
    "    model.parameters(),\n",
    "    lr=0.1, max_iter=1,\n",
    "    max_eval=50000,\n",
    "    tolerance_change=1.0 * np.finfo(float).eps\n",
    ")\n",
    "\n",
    "n_epochs = 2500\n",
    "history = fit(\n",
    "    model, training_set_loader, n_epochs, optimizer_, p=2, verbose=False)\n",
    "print(\"Final Training loss: \", history[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "executionInfo": {
     "elapsed": 534,
     "status": "ok",
     "timestamp": 1682413963824,
     "user": {
      "displayName": "Victor Armegioiu",
      "userId": "10988735183621484296"
     },
     "user_tz": -120
    },
    "id": "zA_eI7fKrwC5",
    "outputId": "6da3f959-7acf-4d1a-c2fc-f56c0856cd25",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.grid(True, which=\"both\", ls=\":\")\n",
    "plt.plot(np.arange(1, n_epochs + 1), np.log10(history), label=\"Train Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 850372,
     "status": "ok",
     "timestamp": 1682414817633,
     "user": {
      "displayName": "Victor Armegioiu",
      "userId": "10988735183621484296"
     },
     "user_tz": -120
    },
    "id": "dQdsctCCnPPQ",
    "outputId": "00b526d3-3ee0-4a43-e819-624e15832a10",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_test_set(n_samples):\n",
    "    torch.manual_seed(34)\n",
    "    inputs_ = (\n",
    "        (max_inputs - min_inputs) * torch.rand((n_samples, d)) + min_inputs)\n",
    "    s_ = torch.zeros((n_samples, d + 1))\n",
    "\n",
    "    print(\"###############################\")\n",
    "    print(\"Generating Test Set\")\n",
    "    for j in range(n_samples):\n",
    "        s_[j, :d] = inputs_[j]\n",
    "        s_[j, -1], _ = solve_heat_eq(inputs_[j])\n",
    "\n",
    "    return s_\n",
    "\n",
    "test_set = generate_test_set(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1682416405878,
     "user": {
      "displayName": "Victor Armegioiu",
      "userId": "10988735183621484296"
     },
     "user_tz": -120
    },
    "id": "Id8okqJhnPPQ",
    "outputId": "73f0c7d1-cb62-418c-9029-e70484565ffa",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_inputs = test_set[:, :d]\n",
    "test_output = test_set[:, -1]\n",
    "\n",
    "test_inputs_scaled = (test_inputs - min_inputs)/(max_inputs - min_inputs)\n",
    "\n",
    "test_pred = model(test_inputs_scaled).reshape(-1, ) \n",
    "err = (\n",
    "    torch.mean(\n",
    "        (test_output - test_pred) ** 2) / torch.mean(test_output ** 2)) ** 0.5\n",
    "\n",
    "print(\"Error Model : \", err.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rlnXYDiMnPPQ",
    "outputId": "19b003b1-551c-46f8-cd15-a2e1f10b2114",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y1=torch.linspace(-5,5, 10000)\n",
    "fig, axs = plt.subplots(2, figsize=(8,12), dpi=200)\n",
    "im1 = axs[0].scatter(test_inputs[:,0], test_inputs[:,1], c=test_output)\n",
    "axs[0].set_xlabel(\"y1\")\n",
    "axs[0].set_ylabel(\"y2\")\n",
    "plt.colorbar(im1,ax=axs[0])\n",
    "axs[0].plot(y1,y1, color=\"grey\", ls=\":\")\n",
    "axs[0].grid(True, which=\"both\", ls=\":\")\n",
    "im2 = axs[1].scatter(test_inputs[:,0], test_inputs[:,1], c=test_pred.detach())\n",
    "axs[1].set_xlabel(\"y1\")\n",
    "axs[1].set_ylabel(\"y2\")\n",
    "plt.colorbar(im2,ax=axs[1])\n",
    "axs[1].plot(y1,y1, color=\"grey\", ls=\":\")\n",
    "axs[1].grid(True, which=\"both\", ls=\":\")\n",
    "axs[0].set_title(\"Exact Solution\")\n",
    "axs[1].set_title(\"Approximate Solution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EebF-3l1nPPR",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Uncertainty Quantification\n",
    "\n",
    "In this subsection we look at the distribution of the flux values, and qualitatively compare the results we get from the surrogate approach of getting the flux vs. the finite difference method.\n",
    "\n",
    "Since different discretizations of $y$ lead to variation in the approximate distribution of $f = L(y)$, we showcase these effects via plotting the distribution corresponding to the $y$'s in the trraining set, versus randomply sampled $y$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2010,
     "status": "ok",
     "timestamp": 1682418594810,
     "user": {
      "displayName": "Victor Armegioiu",
      "userId": "10988735183621484296"
     },
     "user_tz": -120
    },
    "id": "8IGf2_83nPPR",
    "outputId": "712c60bd-1b49-4851-bba4-021bb3f46363",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "inputs_for_UQ = torch.rand((10000, 2))\n",
    "outputs_for_UQ = model(inputs_for_UQ).reshape(-1,).detach()\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "sb.distplot(outputs_for_UQ, label=\"P(f) [f := NN(y), 10k random y samples]\")\n",
    "sb.distplot(output, label=\"P(f) [f := finite_diff(y), 100 Sobol points]\")\n",
    "sb.distplot(test_output,\n",
    "            label=\"P(f) [f := finite_diff(y), 10k random y samples] \")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kiZGwG1OnPPR",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Optimal Design\n",
    "\n",
    "We want to find a value of the input variables $y$ that maximizes the flux $q$:\n",
    "$$\n",
    "y_{opt, exact} = \\arg\\max_{y\\in[0,1]^d} q(y)\n",
    "$$\n",
    "\n",
    "In order to solve the problem we employ the DNNOPT algorithm, that boils down to replacing the model $q(y)$ with the neural network previously trained $q^*(y)$ and solving the maximization problem:\n",
    "$$\n",
    "y_{opt} = \\arg\\max_{y\\in[0,1]^d} q^*(y) \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1682414818130,
     "user": {
      "displayName": "Victor Armegioiu",
      "userId": "10988735183621484296"
     },
     "user_tz": -120
    },
    "id": "zCmkt7tTnPPR",
    "outputId": "db2dbc13-9619-4367-87b4-48657d8820d6",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_opt = torch.tensor(torch.tensor([0.5, 1.24]), requires_grad=True)\n",
    "y_init = torch.clone(y_opt)\n",
    "\n",
    "optimizer = optim.LBFGS(\n",
    "      [y_opt],\n",
    "      lr=float(0.00001),\n",
    "      max_iter=50000,\n",
    "      max_eval=50000,\n",
    "      history_size=100,\n",
    "      line_search_fn=\"strong_wolfe\",\n",
    "      tolerance_change=1.0 * np.finfo(float).eps\n",
    ")\n",
    "\n",
    "optimizer.zero_grad()\n",
    "cost = list([0])\n",
    "\n",
    "def closure():\n",
    "    y_tilde = ((\n",
    "        torch.clamp(y_opt, min=min_inputs, max=max_inputs) - min_inputs) /\n",
    "        (max_inputs - min_inputs))\n",
    "    G = -model(y_tilde)\n",
    "    cost[0] = G\n",
    "    G.backward()\n",
    "    return G\n",
    "\n",
    "\n",
    "optimizer.step(closure=closure)\n",
    "print(\"Minimizer: \", torch.clamp(y_opt, min=min_inputs, max=max_inputs))\n",
    "print(\"Corresponding flux values: \", \n",
    "      model(\n",
    "          (torch.clamp(y_opt, min=min_inputs, max=max_inputs) - min_inputs) / \n",
    "          (max_inputs - min_inputs)\n",
    "          )\n",
    "      )\n",
    "\n",
    "f_opt, (x,ic,u) = solve_heat_eq(\n",
    "    torch.clamp(y_opt, min=min_inputs, max=max_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 652
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1682416603733,
     "user": {
      "displayName": "Victor Armegioiu",
      "userId": "10988735183621484296"
     },
     "user_tz": -120
    },
    "id": "gb_Yho6YsS-r",
    "outputId": "923287d6-60d8-45d9-fc56-e8b05710ac8e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.grid(True, which=\"both\", ls=\":\")\n",
    "plt.plot(x, ic.detach(),label=\"Initial Condition\")\n",
    "plt.plot(x, u.detach(), label=\"Solution at T=0.01\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 726
    },
    "executionInfo": {
     "elapsed": 409649,
     "status": "ok",
     "timestamp": 1682417015563,
     "user": {
      "displayName": "Victor Armegioiu",
      "userId": "10988735183621484296"
     },
     "user_tz": -120
    },
    "id": "nvsEsmbMnPPR",
    "outputId": "83375d33-97af-4acd-89e1-85184d939e4d",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_opt_ex = torch.tensor(torch.tensor([0.5, 1.24]), requires_grad=True)\n",
    "y_init = torch.clone(y_opt_ex)\n",
    "\n",
    "optimizer = optim.LBFGS(\n",
    "    [y_opt_ex],\n",
    "    lr=float(0.00001),\n",
    "    max_iter=50000,\n",
    "    max_eval=50000,\n",
    "    history_size=100,\n",
    "    line_search_fn=\"strong_wolfe\",\n",
    "    tolerance_change=1.0 * np.finfo(float).eps\n",
    ")\n",
    "\n",
    "optimizer.zero_grad()\n",
    "cost = list([0])\n",
    "\n",
    "def closure():\n",
    "    G, _ = solve_heat_eq(\n",
    "        torch.clamp(y_opt_ex, min=min_inputs, max=max_inputs))\n",
    "    G = -G\n",
    "    cost[0] = G\n",
    "    G.backward()\n",
    "    return G\n",
    "\n",
    "\n",
    "optimizer.step(closure=closure)\n",
    "print(\"Exact Minimizer: \", torch.clamp(y_opt_ex, min=min_inputs, max=max_inputs))\n",
    "\n",
    "f_opt_ex, (x,ic,u) = solve_heat_eq(\n",
    "    torch.clamp(y_opt_ex, min=min_inputs, max=max_inputs))\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "plt.grid(True, which=\"both\", ls=\":\")\n",
    "plt.plot(x, ic.detach(),label=\"Initial Condition\")\n",
    "plt.plot(x, u.detach(), label=\"Solution at T=0.01\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 893
    },
    "executionInfo": {
     "elapsed": 4419,
     "status": "ok",
     "timestamp": 1682417465202,
     "user": {
      "displayName": "Victor Armegioiu",
      "userId": "10988735183621484296"
     },
     "user_tz": -120
    },
    "id": "RymIKO72nPPS",
    "outputId": "1c3355e3-5aca-43aa-8fea-f5a8e118239d",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=200)\n",
    "plt.scatter(test_inputs[:,0], test_inputs[:,1], c=test_output)\n",
    "plt.scatter(y_opt_ex[0].detach(), y_opt_ex[1].detach(), marker = \"o\", label = \"Exact Maximizer\")\n",
    "plt.scatter(y_opt[0].detach(), y_opt[1].detach(), marker = \"*\", label = \"Approximate Maximizer\")\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"y1\")\n",
    "plt.ylabel(\"y2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
